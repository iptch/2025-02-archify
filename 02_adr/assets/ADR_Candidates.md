# ADR Candidates & Notes

In our second Workshop we refined use cases and identified/discussed architectural decisions to be refined. 

* (JVI) Which use cases to solve with AI 
* (MKC) API or Self Hosting (consider cost)
* (JVI) Grading: Fully autmated or with Human in the loop
* (IDE) Leverage existing data to improve LLM output (RAG vs. Fine Tunig) 
* How to evaluate Aptitude Exam (Via promt engineering & vector DB)
* Vector DB (Why & How)
* Identify Questions to be reviewed by a human (Aptitude grading)
* How to promt (Aptitude Testing) (per question)
* Prevent Promt Injection Guard Rails (Aptitude)
* Structure Output (Aptitude Test)
* Integration into existing system (Adapter component, Scheduling/Queues, Write back Results (DBs), Changes to existing comonents)
* How to evaluate Architectural Exams (Use evaluation criteria and technical context)
* Enrich Contect for Architectural Exam